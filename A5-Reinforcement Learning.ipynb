{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Solution to the Towers of Hanoi Puzzle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, we will use reinforcement learning to solve the [Towers of Hanoi](https://en.wikipedia.org/wiki/Tower_of_Hanoi) puzzle.  \n",
    "\n",
    "To accomplish this, we will modify the code discussed in lecture for learning to play Tic-Tac-Toe.  Modify the code  so that it learns to solve the three-disk, three-peg\n",
    "Towers of Hanoi Puzzle.  \n",
    "\n",
    "Steps required to do this include the following:\n",
    "\n",
    "  - Represent the state, and use it as a tuple as a key to the Q dictionary.\n",
    "  - Make sure only valid moves are tried from each state.\n",
    "  - Assign reinforcement of $-1$ to each move unless it is a move to the goal state, for which the reinforcement is $0$.  This represents the goal of finding the shortest path to the goal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The disks have been named as 1, 2, and 3, with 1 being the smallest disk and 3 being the largest. The set of disks on a peg has been represented as a list of integers.  Then the state can be a list of three lists.\n",
    "\n",
    "For example, the starting state with all disks being on the left peg would be `[[1, 2, 3], [], []]`.  After moving disk 1 to peg 2, we have `[[2, 3], [1], []]`.\n",
    "\n",
    "To represent that move we just made, we can use a list of two peg numbers, like `[1, 2]`, representing a move of the top disk on peg 1 to peg 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions have been used for this assignment:\n",
    "\n",
    "   - `printState(state)`: prints the state in the form shown below\n",
    "   - `validMoves(state)`: returns list of moves that are valid from `state`\n",
    "   - `makeMove(state, move)`: returns new (copy of) state after move has been applied.\n",
    "   - `trainQ(nRepetitions, learningRate, epsilonDecayFactor, validMovesF, makeMoveF)`: train the Q function for number of repetitions, decaying epsilon at start of each repetition. Returns Q and list or array of number of steps to reach goal for each repetition.\n",
    "   - `testQ(Q, maxSteps, validMovesF, makeMoveF)`: without updating Q, use Q to find greedy action each step until goal is found. Return path of states.\n",
    "   - `stateMoveTuple(state, move)`: returns tuple of state and move.  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from random import choice\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def printState(state):\n",
    "    peg=[['','',''],['','',''],['','','']]\n",
    "    for i in range (0,(len(state))):\n",
    "        if len(state[i])==0:\n",
    "            peg[i][0]=' '\n",
    "            peg[i][1]=' '\n",
    "            peg[i][2]=' '\n",
    "        if len(state[i])==1:\n",
    "            peg[i][0]=' '\n",
    "            peg[i][1]=' '\n",
    "            peg[i][2]=state[i][0]\n",
    "        if len(state[i])==2:\n",
    "            peg[i][0]=' '\n",
    "            peg[i][1]=state[i][0]\n",
    "            peg[i][2]=state[i][1]\n",
    "        if len(state[i])==3:\n",
    "            peg[i][0]=state[i][0]\n",
    "            peg[i][1]=state[i][1]\n",
    "            peg[i][2]=state[i][2]\n",
    "    \n",
    "    for i in range (0,3):\n",
    "        print (peg[0][i],peg[1][i],peg[2][i])\n",
    "    print ('------')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \n",
      "    1\n",
      "3   2\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "state = [[3], [], [1,2]]\n",
    "printState(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stateMoveTuple(state, move):\n",
    "    newState=copy.deepcopy(state)\n",
    "    newMove=copy.deepcopy(move)\n",
    "    for i in range (0,(len(newState))):\n",
    "        newState[i]=tuple(newState[i])\n",
    "    return (tuple(newState),tuple(newMove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validMoves(state):\n",
    "    move = []\n",
    "    for i in range (0,3):\n",
    "        if len(state[i])==0:\n",
    "            continue\n",
    "        else: \n",
    "            for j in range (0,3):\n",
    "                if j == i:\n",
    "                    continue\n",
    "                else:\n",
    "                    if len(state[j])==0:\n",
    "                        move.append([i+1,j+1])\n",
    "                        continue\n",
    "                    elif state[i]<state[j]:\n",
    "                        move.append([i+1,j+1])\n",
    "    return move     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 1], [3, 1], [3, 2]]\n"
     ]
    }
   ],
   "source": [
    "state=[[], [3, 2], [1]]\n",
    "x=validMoves(state)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makeMove(state,move):\n",
    "    #print (state,move)\n",
    "    tempState=copy.deepcopy(state)\n",
    "    list(tempState)\n",
    "    x=tempState[move[0]-1][0]\n",
    "    del tempState[move[0]-1][0]\n",
    "    tempState[move[1]-1]=[x]+tempState[move[1]-1]\n",
    "    return tempState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def foundGoal(board):\n",
    "    if board == [[],[],[1,2,3]]:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def epsilonGreedy(epsilon, Q, state):\n",
    "    validMove = validMoves(state)\n",
    "    if np.random.uniform() < epsilon:       \n",
    "        return validMove[random.randint(0, len(validMove)-1)]\n",
    "    else:\n",
    "        # Greedy Move\n",
    "        Qs = []\n",
    "        for m in validMove:\n",
    "            Qs.append(Q.get(stateMoveTuple(state,m), -1))\n",
    "        #Qs = np.array([Q.get(stateMoveTuple(state, m), 0) for m in validMove]) \n",
    "        return validMove[np.argmax(np.asarray(Qs))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Description For TrainQ Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function was developed by Prof. Charles Anderson for CSU CS 440-Intro to AI and was further modified for this assignment. The initial code was developed for Tic-Tac Toe game and for this assignment we further edited the code to modify the reinforcement. In the this code, the following reinforcement has been provided:\n",
    "\n",
    "    -A Reinforcement of 0 if the Goal is Found\n",
    "    -A Reinforcement of -1 otherwise\n",
    "\n",
    "The moves for every step are obtained from the Epsilon Greedy function (given above), which randomly chooses a move from given list of moves and returns the move with the maximum Q value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainQ(nRepetitions, learningRate, epsilonDecayFactor, validMoves, makeMove):\n",
    "    maxGames = nRepetitions\n",
    "    rho = learningRate\n",
    "    epsilonDecayRate = epsilonDecayFactor\n",
    "    epsilon = 1\n",
    "    Q = {}   \n",
    "    stepSize = []\n",
    "    result=[]\n",
    "    for nGames in range(maxGames):\n",
    "        epsilon *= epsilonDecayRate\n",
    "        step = 0\n",
    "        state = [[1,2,3], [], []] #  start state\n",
    "        done = False\n",
    "        showMoves = False\n",
    "        while not done:        \n",
    "            step += 1\n",
    "            move = epsilonGreedy(epsilon, Q, state)\n",
    "            stateNew = copy.deepcopy(state)\n",
    "            stateNew = makeMove(state,move) \n",
    "            if foundGoal(stateNew):\n",
    "                Q[stateMoveTuple(state, move)] = 0\n",
    "                done = True\n",
    "            if stateMoveTuple(state, move) not in Q:\n",
    "                Q[stateMoveTuple(state, move)] = -1  # initial Q value for new state,move\n",
    "            if step > 1:\n",
    "                Q[stateMoveTuple(stateOld, moveOld)] += rho * (-1+Q[stateMoveTuple(state, move)] - Q[stateMoveTuple(stateOld, moveOld)])\n",
    "            stateOld, moveOld = state, move \n",
    "            state = stateNew\n",
    "        stepSize.append(step)\n",
    "        #print(\"Game: {} took {} steps to find the solution.\\n\".format(nGames + 1, step))\n",
    "        #result.append((nGames + 1, step))\n",
    "    #aveSteps = 0\n",
    "    #for game, steps in result:\n",
    "        #aveSteps += steps\n",
    "    #aveSteps = aveSteps / len(result)\n",
    "    #print(\"The average number of steps for {} games was {}.\\n\".format(len(result), aveSteps))\n",
    "    return Q, stepSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({(((), (1,), (2, 3)), (2, 1)): -1.5,\n",
       "  (((), (1,), (2, 3)), (2, 3)): 0,\n",
       "  (((), (1, 2), (3,)), (2, 1)): -2.000000000008498,\n",
       "  (((), (1, 2), (3,)), (2, 3)): -2.375,\n",
       "  (((), (1, 2), (3,)), (3, 1)): -2.3125,\n",
       "  (((), (1, 2, 3), ()), (2, 1)): -3.943359375,\n",
       "  (((), (1, 2, 3), ()), (2, 3)): -4.25,\n",
       "  (((), (1, 3), (2,)), (2, 1)): -4.3994140625,\n",
       "  (((), (1, 3), (2,)), (2, 3)): -4.16796875,\n",
       "  (((), (1, 3), (2,)), (3, 1)): -4.056640625,\n",
       "  (((), (2,), (1, 3)), (2, 1)): -2.625,\n",
       "  (((), (2,), (1, 3)), (3, 1)): -2.0,\n",
       "  (((), (2,), (1, 3)), (3, 2)): -2.390625,\n",
       "  (((), (2, 3), (1,)), (2, 1)): -4.12109375,\n",
       "  (((), (2, 3), (1,)), (3, 1)): -3.796875,\n",
       "  (((), (2, 3), (1,)), (3, 2)): -3.8515625,\n",
       "  (((), (3,), (1, 2)), (2, 1)): -4.578125,\n",
       "  (((), (3,), (1, 2)), (3, 1)): -4.16796875,\n",
       "  (((), (3,), (1, 2)), (3, 2)): -4.2236328125,\n",
       "  (((1,), (), (2, 3)), (1, 2)): -1.5,\n",
       "  (((1,), (), (2, 3)), (1, 3)): 0,\n",
       "  (((1,), (), (2, 3)), (3, 2)): -2.328125,\n",
       "  (((1,), (2,), (3,)), (1, 2)): -2.0,\n",
       "  (((1,), (2,), (3,)), (1, 3)): -2.0,\n",
       "  (((1,), (2,), (3,)), (2, 3)): -1.000000000000206,\n",
       "  (((1,), (2, 3), ()), (1, 2)): -4.19921875,\n",
       "  (((1,), (2, 3), ()), (1, 3)): -3.8671875,\n",
       "  (((1,), (2, 3), ()), (2, 3)): -4.12890625,\n",
       "  (((1,), (3,), (2,)), (1, 2)): -4.076171875,\n",
       "  (((1,), (3,), (2,)), (1, 3)): -4.162109375,\n",
       "  (((1,), (3,), (2,)), (3, 2)): -4.2705078125,\n",
       "  (((1, 2), (), (3,)), (1, 2)): -2.1328125,\n",
       "  (((1, 2), (), (3,)), (1, 3)): -2.3125,\n",
       "  (((1, 2), (), (3,)), (3, 2)): -2.4375,\n",
       "  (((1, 2), (3,), ()), (1, 2)): -3.890625,\n",
       "  (((1, 2), (3,), ()), (1, 3)): -3.09375,\n",
       "  (((1, 2), (3,), ()), (2, 3)): -3.109375,\n",
       "  (((1, 2, 3), (), ()), (1, 2)): -6.106483459472656,\n",
       "  (((1, 2, 3), (), ()), (1, 3)): -6.0000001590274525,\n",
       "  (((1, 3), (), (2,)), (1, 2)): -4.62109375,\n",
       "  (((1, 3), (), (2,)), (1, 3)): -4.556640625,\n",
       "  (((1, 3), (), (2,)), (3, 2)): -4.74072265625,\n",
       "  (((1, 3), (2,), ()), (1, 2)): -4.04248046875,\n",
       "  (((1, 3), (2,), ()), (1, 3)): -4.509895324707031,\n",
       "  (((1, 3), (2,), ()), (2, 3)): -4.43359375,\n",
       "  (((2,), (), (1, 3)), (1, 2)): -2.75,\n",
       "  (((2,), (), (1, 3)), (3, 1)): -2.3125,\n",
       "  (((2,), (), (1, 3)), (3, 2)): -2.125,\n",
       "  (((2,), (1,), (3,)), (1, 3)): -1.03125,\n",
       "  (((2,), (1,), (3,)), (2, 1)): -2.40625,\n",
       "  (((2,), (1,), (3,)), (2, 3)): -2.25,\n",
       "  (((2,), (1, 3), ()), (1, 3)): -4.2314453125,\n",
       "  (((2,), (1, 3), ()), (2, 1)): -3.78125,\n",
       "  (((2,), (1, 3), ()), (2, 3)): -3.625,\n",
       "  (((2,), (3,), (1,)), (1, 2)): -3.8046875,\n",
       "  (((2,), (3,), (1,)), (3, 1)): -3.6875,\n",
       "  (((2,), (3,), (1,)), (3, 2)): -4.0,\n",
       "  (((2, 3), (), (1,)), (1, 2)): -5.000000021372859,\n",
       "  (((2, 3), (), (1,)), (3, 1)): -5.2965087890625,\n",
       "  (((2, 3), (), (1,)), (3, 2)): -5.108154296875,\n",
       "  (((2, 3), (1,), ()), (1, 3)): -5.4776611328125,\n",
       "  (((2, 3), (1,), ()), (2, 1)): -5.68072509765625,\n",
       "  (((2, 3), (1,), ()), (2, 3)): -5.6025390625,\n",
       "  (((3,), (), (1, 2)), (1, 2)): -4.5263671875,\n",
       "  (((3,), (), (1, 2)), (3, 1)): -4.724609375,\n",
       "  (((3,), (), (1, 2)), (3, 2)): -4.541015625,\n",
       "  (((3,), (1,), (2,)), (2, 1)): -5.12646484375,\n",
       "  (((3,), (1,), (2,)), (2, 3)): -4.8212890625,\n",
       "  (((3,), (1,), (2,)), (3, 1)): -4.96923828125,\n",
       "  (((3,), (1, 2), ()), (1, 3)): -3.00000000017101,\n",
       "  (((3,), (1, 2), ()), (2, 1)): -3.5546875,\n",
       "  (((3,), (1, 2), ()), (2, 3)): -3.8671875,\n",
       "  (((3,), (2,), (1,)), (2, 1)): -4.967041015625,\n",
       "  (((3,), (2,), (1,)), (3, 1)): -4.328125,\n",
       "  (((3,), (2,), (1,)), (3, 2)): -4.0000000022366216},\n",
       " [16,\n",
       "  126,\n",
       "  38,\n",
       "  23,\n",
       "  12,\n",
       "  34,\n",
       "  72,\n",
       "  12,\n",
       "  36,\n",
       "  17,\n",
       "  44,\n",
       "  9,\n",
       "  12,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  7,\n",
       "  7,\n",
       "  10,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainQ(50, 0.5, 0.7, validMoves, makeMove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q, stepsToGoal = trainQ(50, 0.5, 0.7, validMoves, makeMove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18,\n",
       " 69,\n",
       " 41,\n",
       " 72,\n",
       " 36,\n",
       " 7,\n",
       " 40,\n",
       " 15,\n",
       " 10,\n",
       " 35,\n",
       " 9,\n",
       " 31,\n",
       " 7,\n",
       " 12,\n",
       " 49,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 17,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stepsToGoal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Description of TestQ Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function was developed to return the path of states without updating Q. The Q value, previously generated from the TrainQ Function was used to find greedy action each step until goal is found. Since we used a reinforcement of -1 in goal is not found and reinforcement of 0 if the goal is found, we used the 'argmax' function. The move with the highest value of Q is selected as a valid move. This function is performed either until the puzzle is solved or until the Maximum Number of Steps is reached. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testQ(Q, maxSteps, validMovesF, makeMoveF):\n",
    "    path=[]\n",
    "    state=[[1,2,3],[],[]] #Start State\n",
    "    path.append(state)\n",
    "    done=False\n",
    "    step=0\n",
    "    \n",
    "    while (not done and step<maxSteps)  :\n",
    "        step+=1\n",
    "        moves=validMovesF(state)\n",
    "        for m in moves:\n",
    "            Qs = np.array([Q.get(stateMoveTuple(state, m), 0) for m in moves]) \n",
    "        move = moves[np.argmax(Qs)]    \n",
    "        newstate = makeMoveF(state, move)\n",
    "        path.append(newstate)\n",
    "        if foundGoal(newstate):\n",
    "            done = True\n",
    "        state = newstate\n",
    "        \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = testQ(Q, 20, validMoves, makeMove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 2, 3], [], []],\n",
       " [[2, 3], [], [1]],\n",
       " [[3], [2], [1]],\n",
       " [[3], [1, 2], []],\n",
       " [[], [1, 2], [3]],\n",
       " [[1], [2], [3]],\n",
       " [[1], [], [2, 3]],\n",
       " [[], [1], [2, 3]],\n",
       " [[], [], [1, 2, 3]]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    \n",
      "2    \n",
      "3    \n",
      "------\n",
      "\n",
      "     \n",
      "2    \n",
      "3   1\n",
      "------\n",
      "\n",
      "     \n",
      "     \n",
      "3 2 1\n",
      "------\n",
      "\n",
      "     \n",
      "  1  \n",
      "3 2  \n",
      "------\n",
      "\n",
      "     \n",
      "  1  \n",
      "  2 3\n",
      "------\n",
      "\n",
      "     \n",
      "     \n",
      "1 2 3\n",
      "------\n",
      "\n",
      "     \n",
      "    2\n",
      "1   3\n",
      "------\n",
      "\n",
      "     \n",
      "    2\n",
      "  1 3\n",
      "------\n",
      "\n",
      "    1\n",
      "    2\n",
      "    3\n",
      "------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in path:\n",
    "    printState(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Download and extract `A5grader.py` from [A5grader.tar](http://www.cs.colostate.edu/~anderson/cs440/notebooks/A5grader.tar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing validMoves([[1], [2], [3]])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[1, 2], [1, 3], [2, 3]]\n",
      "\n",
      "Testing validMoves([[], [], [1, 2, 3]])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[3, 1], [3, 2]]\n",
      "\n",
      "Testing makeMove([[], [], [1, 2, 3]], [3, 2])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[], [1], [2, 3]]\n",
      "\n",
      "Testing makeMove([[2], [3], [1]], [1, 2])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[], [2, 3], [1]]\n",
      "\n",
      "Testing   Q, steps = trainQ(1000, 0.5, 0.7, validMoves, makeMove).\n",
      "\n",
      "--- 10/10 points. Q dictionary has correct number of entries.\n",
      "\n",
      "--- 10/10 points. The mean of the number of steps is 8.43 which is correct.\n",
      "\n",
      "Testing   path = testQ(Q, 20, validMoves, makeMove).\n",
      "\n",
      "--- 20/20 points. Correctly returns path of length 8, less than 10.\n",
      "\n",
      "Intro to AI Execution Grade is 80/80\n",
      "\n",
      " Remaining 20 points will be based on your text describing the trainQ and test! functions.\n",
      "\n",
      "Intro to AI FINAL GRADE is __/100\n"
     ]
    }
   ],
   "source": [
    "%run -i A5grader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Towers of Hanoi with 4 Disks and 3 Pegs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify your code to solve the Towers of Hanoi puzzle with 4 disks instead of 3.  Name your functions\n",
    "\n",
    "    - printState_4disk\n",
    "    - validMoves_4disk\n",
    "    - makeMove_4disk\n",
    "\n",
    "Find values for number of repetitions, learning rate, and epsilon decay factor for which trainQ learns a Q function that testQ can use to find the shortest solution path.  Include the output from the successful calls to trainQ and testQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printState_4disk(state):\n",
    "    peg=[['','','',''],['','','',''],['','','','']]\n",
    "    for i in range (0,(len(state))):\n",
    "        if len(state[i])==0:\n",
    "            peg[i][0]=' '\n",
    "            peg[i][1]=' '\n",
    "            peg[i][2]=' '\n",
    "            peg[i][3]=' '\n",
    "        if len(state[i])==1:\n",
    "            peg[i][0]=' '\n",
    "            peg[i][1]=' '\n",
    "            peg[i][2]=' '\n",
    "            peg[i][3]=state[i][0]\n",
    "        if len(state[i])==2:\n",
    "            peg[i][0]=' '\n",
    "            peg[i][1]=' '\n",
    "            peg[i][2]=state[i][0]\n",
    "            peg[i][3]=state[i][1]\n",
    "        if len(state[i])==3:\n",
    "            peg[i][0]=' '\n",
    "            peg[i][1]=state[i][0]\n",
    "            peg[i][2]=state[i][1]\n",
    "            peg[i][3]=state[i][2]\n",
    "        if len(state[i])==4:\n",
    "            peg[i][0]=state[i][0]\n",
    "            peg[i][1]=state[i][1]\n",
    "            peg[i][2]=state[i][2]\n",
    "            peg[i][3]=state[i][3]\n",
    "            \n",
    "    for i in range (0,4):\n",
    "        print (peg[0][i],peg[1][i],peg[2][i])\n",
    "    print ('------')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \n",
      "     \n",
      "2    \n",
      "3 1 4\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "state=[[2,3],[1],[4]]\n",
    "printState_4disk(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validMoves_4disk(state):\n",
    "    move = []\n",
    "    for i in range (0,3):\n",
    "        if len(state[i])==0:\n",
    "            continue\n",
    "        else: \n",
    "            for j in range (0,3):\n",
    "                if j == i:\n",
    "                    continue\n",
    "                else:\n",
    "                    if len(state[j])==0:\n",
    "                        move.append([i+1,j+1])\n",
    "                        continue\n",
    "                    elif state[i]<state[j]:\n",
    "                        move.append([i+1,j+1])\n",
    "    return move     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [1, 3], [3, 2]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state=[[2,1],[4],[3]]\n",
    "validMoves_4disk(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeMove_4disk(state,move):\n",
    "    #print (state,move)\n",
    "    tempState=copy.deepcopy(state)\n",
    "    list(tempState)\n",
    "    x=tempState[move[0]-1][0]\n",
    "    del tempState[move[0]-1][0]\n",
    "    tempState[move[1]-1]=[x]+tempState[move[1]-1]\n",
    "    return tempState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [2, 4], [3]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move=[1,2]\n",
    "makeMove_4disk(state,move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TrainQ Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def foundGoal_4disk(board):\n",
    "    if board == [[],[],[1,2,3,4]]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def trainQ_4disk(nRepetitions, learningRate, epsilonDecayFactor, validMoves, makeMove):\n",
    "    maxGames = nRepetitions\n",
    "    rho = learningRate\n",
    "    epsilonDecayRate = epsilonDecayFactor\n",
    "    epsilon = 1\n",
    "    Q = {}   \n",
    "    stepSize = []\n",
    "    result=[]\n",
    "    for nGames in range(maxGames):\n",
    "        epsilon *= epsilonDecayRate\n",
    "        step = 0\n",
    "        state = [[1,2,3,4], [], []] #  start state\n",
    "        done = False\n",
    "        showMoves = False\n",
    "        while not done:        \n",
    "            step += 1\n",
    "            move = epsilonGreedy(epsilon, Q, state)\n",
    "            stateNew = copy.deepcopy(state)\n",
    "            stateNew = makeMove(state,move) \n",
    "            if foundGoal_4disk(stateNew):\n",
    "                Q[stateMoveTuple(state, move)] = 0\n",
    "                done = True\n",
    "            if stateMoveTuple(state, move) not in Q:\n",
    "                Q[stateMoveTuple(state, move)] = -1  # initial Q value for new state,move\n",
    "            if step > 1:\n",
    "                Q[stateMoveTuple(stateOld, moveOld)] += rho * (-1+Q[stateMoveTuple(state, move)] - Q[stateMoveTuple(stateOld, moveOld)])\n",
    "            stateOld, moveOld = state, move \n",
    "            state = stateNew\n",
    "        stepSize.append(step)\n",
    "        #print(\"Game: {} took {} steps to find the solution.\\n\".format(nGames + 1, step))\n",
    "        #result.append((nGames + 1, step))\n",
    "    #aveSteps = 0\n",
    "    #for game, steps in result:\n",
    "        #aveSteps += steps\n",
    "    #aveSteps = aveSteps / len(result)\n",
    "    #print(\"The average number of steps for {} games was {}.\\n\".format(len(result), aveSteps))\n",
    "    return Q, stepSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "#### Case 1\n",
    "Number of Repetitions: 70\n",
    "Learning Rate: 0.5\n",
    "Epsilon Decay Factor:0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q, stepsToGoal = trainQ_4disk(100, 0.5, 0.7, validMoves_4disk, makeMove_4disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[390,\n",
       " 145,\n",
       " 284,\n",
       " 93,\n",
       " 360,\n",
       " 168,\n",
       " 57,\n",
       " 109,\n",
       " 178,\n",
       " 25,\n",
       " 83,\n",
       " 176,\n",
       " 57,\n",
       " 204,\n",
       " 32,\n",
       " 50,\n",
       " 66,\n",
       " 38,\n",
       " 85,\n",
       " 27,\n",
       " 128,\n",
       " 34,\n",
       " 36,\n",
       " 20,\n",
       " 44,\n",
       " 119,\n",
       " 37,\n",
       " 85,\n",
       " 23,\n",
       " 47,\n",
       " 17,\n",
       " 34,\n",
       " 16,\n",
       " 119,\n",
       " 31,\n",
       " 20,\n",
       " 56,\n",
       " 18,\n",
       " 33,\n",
       " 15,\n",
       " 36,\n",
       " 22,\n",
       " 15,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 59,\n",
       " 16,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 66,\n",
       " 15,\n",
       " 15,\n",
       " 17,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stepsToGoal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "#### Case 2\n",
    "Number of Repetitions: 80\n",
    "Learning Rate: 0.4\n",
    "Epsilon Decay Factor:0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q, stepsToGoal = trainQ_4disk(100, 0.4, 0.8, validMoves_4disk, makeMove_4disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[890,\n",
       " 123,\n",
       " 143,\n",
       " 344,\n",
       " 128,\n",
       " 281,\n",
       " 198,\n",
       " 178,\n",
       " 38,\n",
       " 52,\n",
       " 66,\n",
       " 79,\n",
       " 46,\n",
       " 132,\n",
       " 46,\n",
       " 42,\n",
       " 43,\n",
       " 82,\n",
       " 30,\n",
       " 58,\n",
       " 134,\n",
       " 33,\n",
       " 30,\n",
       " 54,\n",
       " 34,\n",
       " 31,\n",
       " 58,\n",
       " 92,\n",
       " 27,\n",
       " 28,\n",
       " 89,\n",
       " 28,\n",
       " 111,\n",
       " 33,\n",
       " 18,\n",
       " 23,\n",
       " 110,\n",
       " 18,\n",
       " 57,\n",
       " 22,\n",
       " 17,\n",
       " 37,\n",
       " 20,\n",
       " 25,\n",
       " 85,\n",
       " 16,\n",
       " 39,\n",
       " 16,\n",
       " 63,\n",
       " 30,\n",
       " 19,\n",
       " 15,\n",
       " 18,\n",
       " 36,\n",
       " 56,\n",
       " 19,\n",
       " 15,\n",
       " 23,\n",
       " 15,\n",
       " 18,\n",
       " 15,\n",
       " 17,\n",
       " 85,\n",
       " 15,\n",
       " 31,\n",
       " 15,\n",
       " 17,\n",
       " 15,\n",
       " 17,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stepsToGoal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TestQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testQ_4disk(Q, maxSteps, validMovesF, makeMoveF):\n",
    "    path=[]\n",
    "    state=[[1,2,3,4],[],[]] #Start State\n",
    "    path.append(state)\n",
    "    done=False\n",
    "    step=0\n",
    "    \n",
    "    while (not done and step<maxSteps)  :\n",
    "        step+=1\n",
    "        moves=validMovesF(state)\n",
    "        for m in moves:\n",
    "            Qs = np.array([Q.get(stateMoveTuple(state, m), 0) for m in moves]) \n",
    "        move = moves[np.argmax(Qs)]    \n",
    "        newstate = makeMoveF(state, move)\n",
    "        path.append(newstate)\n",
    "        if foundGoal_4disk(newstate):\n",
    "            done = True\n",
    "        state = newstate\n",
    "        \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 2, 3, 4], [], []],\n",
       " [[2, 3, 4], [1], []],\n",
       " [[3, 4], [1], [2]],\n",
       " [[3, 4], [], [1, 2]],\n",
       " [[4], [3], [1, 2]],\n",
       " [[1, 4], [3], [2]],\n",
       " [[1, 4], [2, 3], []],\n",
       " [[4], [1, 2, 3], []],\n",
       " [[], [1, 2, 3], [4]],\n",
       " [[], [2, 3], [1, 4]],\n",
       " [[2], [3], [1, 4]],\n",
       " [[1, 2], [3], [4]],\n",
       " [[1, 2], [], [3, 4]],\n",
       " [[2], [1], [3, 4]],\n",
       " [[], [1], [2, 3, 4]],\n",
       " [[], [], [1, 2, 3, 4]]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = testQ_4disk(Q, 20, validMoves_4disk, makeMove_4disk)\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    \n",
      "2    \n",
      "3    \n",
      "4    \n",
      "------\n",
      "\n",
      "     \n",
      "2    \n",
      "3    \n",
      "4 1  \n",
      "------\n",
      "\n",
      "     \n",
      "     \n",
      "3    \n",
      "4 1 2\n",
      "------\n",
      "\n",
      "     \n",
      "     \n",
      "3   1\n",
      "4   2\n",
      "------\n",
      "\n",
      "     \n",
      "     \n",
      "    1\n",
      "4 3 2\n",
      "------\n",
      "\n",
      "     \n",
      "     \n",
      "1    \n",
      "4 3 2\n",
      "------\n",
      "\n",
      "     \n",
      "     \n",
      "1 2  \n",
      "4 3  \n",
      "------\n",
      "\n",
      "     \n",
      "  1  \n",
      "  2  \n",
      "4 3  \n",
      "------\n",
      "\n",
      "     \n",
      "  1  \n",
      "  2  \n",
      "  3 4\n",
      "------\n",
      "\n",
      "     \n",
      "     \n",
      "  2 1\n",
      "  3 4\n",
      "------\n",
      "\n",
      "     \n",
      "     \n",
      "    1\n",
      "2 3 4\n",
      "------\n",
      "\n",
      "     \n",
      "     \n",
      "1    \n",
      "2 3 4\n",
      "------\n",
      "\n",
      "     \n",
      "     \n",
      "1   3\n",
      "2   4\n",
      "------\n",
      "\n",
      "     \n",
      "     \n",
      "    3\n",
      "2 1 4\n",
      "------\n",
      "\n",
      "     \n",
      "    2\n",
      "    3\n",
      "  1 4\n",
      "------\n",
      "\n",
      "    1\n",
      "    2\n",
      "    3\n",
      "    4\n",
      "------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in path:\n",
    "    printState_4disk(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "Two cases were presented for the Optimal Solution for the this problem. The values for number of repetitions, learning rate, and epsilon decay factor for which trainQ learns a Q function that testQ can use to find the shortest solution path was given above.  The output with  successful calls to trainQ and testQ function were presented."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
